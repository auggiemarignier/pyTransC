{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be3125f-03e9-4c1a-91e4-98d8677ae19c",
   "metadata": {},
   "source": [
    "## Example of Trans-C sampling across independent model states\n",
    "\n",
    "This notebook demonstrates sampling across unormalized multi-dimensional Gaussian PDFs in states with non-consequtive dimensions\n",
    "using the Pseudo-Prior sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c36aa4-4cc4-4ca2-b984-26cfde5d068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general python utility packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import corner\n",
    "import time\n",
    "from collections import Counter\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import pickle as pickle\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad6b637-5a71-42f3-8e95-c53b2304f43d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### TransC class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b54a941c-6cc0-4b01-8fbd-bfd338f01e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyTransC import TransC_Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99479993-1f28-4763-8b63-d56aa265bd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_extend(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list.extend(row)\n",
    "    return np.array(flat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c43725-4269-412e-809b-9848cc3c79a1",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b411a522-0f82-4fc1-84fe-4807e8a8fb2e",
   "metadata": {},
   "source": [
    "## Example set up: Three states with non-consecutive dimensions, 3D, 5D and 10D Gaussians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f529eb-993e-4fcd-a4f3-6c9174d2e0ea",
   "metadata": {},
   "source": [
    "Set some global control parameters for all examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afd65bdc-56dd-4a9b-977e-f3c3b6b8bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting = True      # Create some diagnostic displays of outputs\n",
    "parallel = False     # Use parallel computation for sampling\n",
    "autopseudo = True    # Use automatic generation of pseudo-prior function, as alternate to user specified Gaussian.\n",
    "autothin = False     # Thin internally generated within state posterior ensembles by their auto-correlation \n",
    "                     # (This can take additional compute time, and is not necessary if input ensembles are already independent.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4376dd8-ae44-4156-8b8a-26646398e037",
   "metadata": {},
   "source": [
    "Define log posterior PDF for three states with Gaussian posterior PDF.\n",
    "\n",
    "First we set up three unormalized Gaussian states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f231f7f8-30b7-4a57-8184-36f5b96ac70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up PDFs in each state\n",
    "nstates = 3                                      # Number of states\n",
    "ndims = [3,5,10]                                 # Number of dimensions for each state\n",
    "weights = [0.56,0.3,0.14]                        # weights for each state (become true values for relative evidence/marginal Likelihoods.\n",
    "trueML = weights/np.sum(weights)                 # true values of marginal Likelihoods/relative evidences\n",
    "mu = [[0.8,0.8,0.8],[0.3 for i in range(5)],[0.5 for i in range(10)]] # Gaussian means for each state\n",
    "sig = [0.02,0.05,0.08]                           # standard deviations of Gaussians in each state\n",
    "cov = [np.diag(np.ones(ndims[i])*sig[i]**2) for i in range(nstates)] # covariance matrices for each state\n",
    "if(True):                                        # rotate the covariance matrices\n",
    "    np.random.seed(210165)\n",
    "    new_cov = []\n",
    "    for i in range(nstates):\n",
    "        rotation_matrix = np.random.rand(ndims[i],ndims[i])-0.5\n",
    "        new_cov.append(rotation_matrix @ cov[i] @ rotation_matrix.T)\n",
    "    cov = new_cov\n",
    "icov = [1./cov[0],np.linalg.inv(cov[1]),np.linalg.inv(cov[2])] # inverse covariance matrices for each state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d9b86f-e644-43cc-9272-2c2893fbca7c",
   "metadata": {},
   "source": [
    "### Log-posteripr PDF\n",
    "Define log_posterior function using these Gaussian PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4401462-302c-44e7-8fd7-b48f36d0ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_posterior(x,state,ndims,mu,cov,weights,icov=False): # Multi-state log Posterior PDF evaluation (unormalised) for three multi-dimensional Gaussians\n",
    "    w = weights[state]\n",
    "    mean = mu[state]\n",
    "    covar = cov[state]\n",
    "    r = mean-x \n",
    "    if(icov):\n",
    "        if(ndims[state] == 1): \n",
    "            log_const = np.log(w) - 0.5*len(x)*np.log(2*np.pi) - 0.5*np.log(covar[0])\n",
    "            out = log_const-0.5 * np.dot(r,r)*(covar[0])\n",
    "        else:\n",
    "            log_const = np.log(w) - 0.5*len(x)*np.log(2*np.pi) - 0.5*np.log(np.linalg.det(covar)) \n",
    "            out = log_const-0.5 * np.dot(r, np.dot(covar, r))\n",
    "    else:\n",
    "        if(ndims[state] == 1): \n",
    "            log_const = np.log(w) - 0.5*len(x)*np.log(2*np.pi) - 0.5*np.log(covar[0])\n",
    "            out = log_const-0.5 * np.dot(r,r)/(covar[0])\n",
    "        else:\n",
    "            log_const = np.log(w) - 0.5*len(x)*np.log(2*np.pi) - 0.5*np.log(np.linalg.det(covar)) \n",
    "            out = log_const-0.5 * np.dot(r, np.linalg.solve(covar, r))\n",
    "    return out\n",
    "    \n",
    "log_posterior_args = [ndims,mu,cov,weights]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f8cb07-204a-4306-8207-9579d2e8721f",
   "metadata": {},
   "source": [
    "### Starting points for MCMC samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2569f9ca-c73c-4723-bc96-38ca3894e527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum likelihood estimates:\n",
      "x_ml = 0.800\n",
      "x_ml = 0.300\n",
      "x_ml = 0.500\n"
     ]
    }
   ],
   "source": [
    "# first we optimize each state to find good starting point for all McMC samplers\n",
    "np.random.seed(42)\n",
    "if(True):\n",
    "    nll = lambda *args: -log_posterior(*args)\n",
    "    initial = np.array([0.5])\n",
    "    ml = []\n",
    "    print(\"Maximum likelihood estimates:\")\n",
    "    for i in range(nstates):\n",
    "        soln = minimize(nll, initial, args=(i,ndims,mu,cov,weights))\n",
    "        ml.append(soln.x)\n",
    "        print(\"x_ml = {0:.3f}\".format(soln.x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af90c625-577c-4df3-af5b-53545777620b",
   "metadata": {},
   "source": [
    "### Decide on normalized pseudo prior PDFs\n",
    "\n",
    "Here we demonstrate how to define a pseudo_prior PDF, by either\n",
    "\n",
    "    - fitting a mixture model approximation to existing ensembles (autopseudo=True),\n",
    "\n",
    "    - defining a Gaussian within each state (autopseudo=False)\n",
    "\n",
    "Our implementation of an automatic pseudo prior function, uses the supplied class function `build_pseudo_prior`.  This class function is essentially a wrapper routine around calls to `run_mcmc_per_state` and `run_fitmixture`, similar to the pre calculation below for `run-ens-sampler`. To encourage independence of samples produced `run_mcmc_per_state`, the ensembles input to `run_fitmixture` are thinned using the Markov chain correlation times calculated for each state.\n",
    "\n",
    "Use of `autothin=True` means that auto correlation times are calculated for each space and the ensembles used to construct pseudo_priors are thinned by this value. This slows down the procedure because the auto correlation calculation is relatively slow.\n",
    "\n",
    "In truth the question of how to build a normalized PDF approximation of the posterior (for use as a pseudo-prior) is an open question, and so `build_pseudo_prior` should be taken as a simple example implementation of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26a078cb-2187-4d7e-b06c-2c5074948401",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(autopseudo): # Automatic pseudo prior function\n",
    "    nwalkers_auto = 32                                                # Number of walkers for auto pseudo prior fitting\n",
    "    nsteps_auto = 1000                                               # Number of chain steps for auto pseudo prior fitting\n",
    "    pos_states = np.random.choice(np.arange(nstates),nwalkers_auto) # Initial states of each walker for auto pseudo prior fitting\n",
    "    pos = []\n",
    "    for i in range(nstates): # generate starting points for each chain in each state\n",
    "        pos.append(ml[i] + 1e-4 * np.random.randn(nwalkers_auto, ndims[i])) # add random perturbation to maximum Likelihood models\n",
    "    \n",
    "    tcs = TransC_Sampler(nstates,ndims) # create instances of states\n",
    "    auto_log_pseudo_prior = tcs.build_auto_pseudo_prior(pos,log_posterior,log_posterior_args=log_posterior_args,\n",
    "                                                   nwalkers=nwalkers_auto,nsamples=nsteps_auto,autothin=autothin,parallel=parallel)\n",
    "\n",
    "    log_pseudo_prior_args = []   # additional argument list beyond (x,state) for log_pseudo_prior function\n",
    "\n",
    "    def log_pseudo_prior(x,state,returndeviate=False):               # multi-state log pseudo-prior density and deviate generator\n",
    "        return auto_log_pseudo_prior(x,state,returndeviate=returndeviate)\n",
    "\n",
    "else:  # A Gaussian pseudo prior within each model state\n",
    "\n",
    "    def log_pseudo_prior(x,state,ndims,returndeviate=False):               # multi-state log pseudo-prior density and deviate generator\n",
    "        mu = [[0.6],[0.7,0.7,0.7],[0.2,0.2,0.2,0.2,0.2]]                   # Gaussian means for each state\n",
    "        sig = [0.025,0.055,0.085]                                          # standard deviations of isotropic Gaussians in each state\n",
    "        cov = [np.array([sig[0]**2]),np.diag(np.ones(ndims[1])*sig[1]**2),\n",
    "                np.diag(sig[2]**2*np.ones(ndims[2]))]                       # covariance matrices for each state\n",
    "        if(returndeviate):\n",
    "            x = stats.multivariate_normal.rvs(mean=mu[state],cov=cov[state]) # spherical multi-dimensional Gaussian\n",
    "            logppx = stats.multivariate_normal.logpdf(x,mean=mu[state],cov=cov[state]) # spherical multi-dimensional Gaussian\n",
    "            if(type(x) != np.ndarray): x = np.array([x]) # deal with 1D case which returns a scalar\n",
    "            return logppx,x\n",
    "        else:\n",
    "            return stats.multivariate_normal.logpdf(x,mean=mu[state],cov=cov[state]) # spherical multi-dimensional Gaussian \n",
    "\n",
    "    log_pseudo_prior_args = [ndims]   # additional argument list beyond (x,state)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec44d92d-d3ce-4a51-8554-9d6247fb7710",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5a37bf-8505-4527-a00e-ae6ab1ec5151",
   "metadata": {},
   "source": [
    "Now we are ready to apply the three algorithms to sampling over the model states."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e51c05-7cae-4799-9c3f-ec551f7afc21",
   "metadata": {},
   "source": [
    "## Trans-C samping across model states with algorithm 2: The Pseudo sampler "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73a8b15-6d77-4c70-8f8a-61a8d34806a3",
   "metadata": {},
   "source": [
    "Here we demonstrate use of the *Pseudo-prior sampler*.\n",
    "\n",
    "This formulation is equivalent to the product space algorithm with the proposal for the other state variables equal to the pseudo-prior, for which moves are then accepted with probability one. As a consequence  the only pair of model states that need be considered is the k and k' states (i.e. same as in RJ-transD). \n",
    "\n",
    "- For within-state moves the acceptance is the usual M-H condition with proposal = to users choice for that state, defined by routine `log_proposal`\n",
    "  This can be any perturbative proposal PDF designed by the user, or an automatic one found by fitting a Gaussian mixture model to some trial samples, which is performed by the class function `build_pseudo_prior`.\n",
    "\n",
    "- For between-state moves we assume that only the state index changes, k -> k', and hence the model in state k' must be a draw from the pseduo prior for that state. The acceptance term then only involves the likelihood ratio and the pseudo-prior ratio for the two states.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1e7c7a9-22a6-451b-94d3-565b00b50d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model proposal for each state\n",
    "def log_proposal(xc,state,ndims):  # defines a pseudo-prior of an isotropic Gaussian in dimension of input point\n",
    "\n",
    "    use_pseudo_prior = True\n",
    "    use_pseudo_prior = False\n",
    "    if(use_pseudo_prior):  # use the pseudo-prior in each state as the proposal distribution\n",
    "        lpseudop, pmodel = auto_log_pseudo_prior(None,state,returndeviate=True)  # generate deviate from pseudo prior in current state\n",
    "        lpseudoc = auto_log_pseudo_prior(xc,state)                               # log pseudo-prior of current chain model\n",
    "        logpert = lpseudoc - lpseudop  # log difference in pseduo-priors\n",
    "        return logpert,pmodel\n",
    "    else:                                # use a symmetric Gaussian in each state as the proposal distribution\n",
    "        sig = [0.04,0.04,0.04]           # Gaussian centred on current chain location\n",
    "        cov = [np.diag(np.ones(ndims[i])*sig[i]**2) for i in range(nstates)] # covariance matrices for each state\n",
    "\n",
    "        x = xc + stats.multivariate_normal.rvs(mean=np.zeros(ndims[state]),cov=cov[state]) # spherical multi-dimensional Gaussian\n",
    "        logpert = 0.0 # log ratio for symmetric proposal\n",
    "        if(type(x) != np.ndarray): x = np.array([x]) # deal with 1D case which returns a scalar\n",
    "        return logpert,x # return log of pseudo prior density and location (as 1D array)\n",
    "    \n",
    "log_proposal_args = [ndims]    # additional argument list beyond (x,state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d422bfe-acb9-46f0-86a8-1de861d20759",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# perform initiation of IS-sampler\n",
    "tcs2 = TransC_Sampler(nstates,ndims) # create instances of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f156a0-c48b-47b1-90c9-5ffea627218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo prior proposal algorithm set up\n",
    "nwalkers_pp = 32                                               # Number of walkers for product space\n",
    "nsteps_pp = 100000                                              # Number of chain steps for product space\n",
    "pos_states = np.random.choice(np.arange(nstates),nwalkers_pp)  # Initial states of each walker\n",
    "pos = []\n",
    "for i in range(nwalkers_pp): # generate starting points for each walker\n",
    "    pos.append(ml[pos_states[i]] + 1e-4 * np.random.randn(ndims[pos_states[i]])) # add random perturbation to maximum Likelihood models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae6d6fe-9ca5-4687-9540-b9271fa8d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running pseudo-prior trans-D sampler\n",
      "\n",
      "Number of walkers               :  32\n",
      "Number of states being sampled  :  3\n",
      "Dimensions of each state        :  [3, 5, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████████████████▉                                                                                    | 9/32 [01:16<03:14,  8.45s/it]"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "tcs2.run_pseudo_sampler(nwalkers_pp,\n",
    "                 nsteps_pp,\n",
    "                 pos,\n",
    "                 pos_states,\n",
    "                 log_posterior,\n",
    "                 log_pseudo_prior,\n",
    "                 log_proposal,\n",
    "                 log_posterior_args=log_posterior_args,\n",
    "                 log_pseudo_prior_args=log_pseudo_prior_args,\n",
    "                 log_proposal_args=log_proposal_args,\n",
    "                 parallel=parallel,\n",
    "                 progress=True)\n",
    "elapsed_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c7304d-4e7e-42f5-a75e-7da073cdaf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some diagnostics\n",
    "key = tcs2\n",
    "print('\\n Algorithm type                                   :', key.alg)\n",
    "# extract trans-D samples and chains\n",
    "discard = 0                  # chain burnin\n",
    "thin = 15                    # chain thinning\n",
    "thin = 1                    # chain thinning\n",
    "chain,states_chain = key.get_visits_to_states(discard=discard,thin=thin,normalize=True,walker_average='median',return_samples=True)\n",
    "\n",
    "print(' Total number of state changes for all walkers    :',key.total_state_changes)\n",
    "print(' Number of state changes for each walker          :\\n',*key.state_changes_perwalker)\n",
    "print(' Acceptance rates for walkers within states:  \\n',key.accept_within_per_walker,'\\n')\n",
    "print(' Acceptance rates for walkers between states: \\n',key.accept_between_per_walker,'\\n')\n",
    "print(' Average % acceptance rate for within states      :',np.round(key.accept_within,2))\n",
    "print(' Average % acceptance rate for between states     :',np.round(key.accept_between,2))\n",
    "print(' Auto correlation time for between state sampling :',np.round(key.autocorr_time_for_between_state_jumps,3))\n",
    "print(' True relative marginal Likelihoods               :', trueML)\n",
    "print(' Estimated relative evidences                     :', key.relative_marginal_likelihoods)\n",
    "print(' Elapsed time.                                    :', np.round(elapsed_time,2),'s \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a0c243-8393-4911-a8b2-d95c296c83e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot relative number of visit to each state along the chain\n",
    "if(plotting):\n",
    "    fig, axes = plt.subplots(figsize=(8,6))\n",
    "    if(chain.ndim == 3): # plot chains for each state and walker\n",
    "        plt.semilogx(chain.reshape(np.shape(chain)[0],-1),lw=0.75)\n",
    "    elif(chain.ndim==2): # plot chains for each state average over walkers\n",
    "        plt.semilogx(chain.reshape(np.shape(chain)[0],-1),lw=0.75,label=['State 1','State 2','State 3'])\n",
    "        plt.legend()\n",
    "    plt.xlabel('Chain step')\n",
    "    plt.ylabel('Relative Evidence')\n",
    "    plt.plot(len(chain)*1.3,trueML[0],'bo')\n",
    "    plt.plot(len(chain)*1.3,trueML[1],'o',color='orange')\n",
    "    plt.plot(len(chain)*1.3,trueML[2],'go')\n",
    "    plt.title(' Convergence of algorithm: '+key.alg)\n",
    "    #plt.savefig('convergence_pseudo_3-5-10.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122e7624-52a7-44bd-bc48-683e309f4113",
   "metadata": {},
   "source": [
    "Coloured dots show the true relative normalization constants for each Gaussian. As you can see the chains of the Product-space sampler are \n",
    "converging, and visiting each state in proportion to the correct normalization constant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee9b7b0-17bc-46ad-b921-05a94ba1ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot chain states\n",
    "if(plotting):\n",
    "    # plot chains for each state and walker\n",
    "    plt.semilogx(states_chain.reshape(np.shape(states_chain)[0],-1),lw=0.75)\n",
    "    plt.xlabel(' Step number')\n",
    "    plt.ylabel(' States')\n",
    "    title = ' States of '+str(nwalkers_pp)+' chains: '+key.alg\n",
    "    plt.title(title)\n",
    "    #plt.savefig('convergence.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7a20f1-b6a7-485d-bef8-303fe6ed25bc",
   "metadata": {},
   "source": [
    "This plot shows the movement of each chain between states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f224c11b-f33e-49ac-bdd6-35727753794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count visits to each state by Trans-D mcmc\n",
    "if(plotting):\n",
    "    h=np.zeros(key.nstates)\n",
    "    h[list(Counter(states_chain.reshape(-1)).keys())] = list(Counter(states_chain.reshape(-1)).values())\n",
    "    h/=np.sum(h)\n",
    "\n",
    "    # plot histogram of frequency of visits to each state\n",
    "\n",
    "    labels = (\"State 1\", \"State 2\", \"State 3\")\n",
    "    labels = ['State '+str(i+1) for i in np.arange(nstates)]\n",
    "\n",
    "    x = np.arange(nstates)  # the label locations\n",
    "    width = 0.25  # the width of the bars\n",
    "    multiplier = 0\n",
    "\n",
    "    fig, ax = plt.subplots(layout='constrained')\n",
    "\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, np.round(h,3), width, label=key.alg,color='skyblue')\n",
    "    #rects = ax.bar(x + offset, np.round(h,3), width, label='Trans-D',color='lightcoral')\n",
    "    ax.bar_label(rects, padding=3)\n",
    "    multiplier += 1\n",
    "    offset = width * multiplier+0.05\n",
    "    rects = ax.bar(x + offset, np.round(trueML,3), width, label='True',color='seagreen')\n",
    "    ax.bar_label(rects, padding=3)\n",
    "    multiplier += 1\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel(' Proportion of visits to each state')\n",
    "    ax.set_title('Relative Evidence')\n",
    "    ax.set_xticks(x + width/2, labels)\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_ylim(0.,np.max(np.maximum(h,trueML))*1.1)\n",
    "    #plt.savefig('Marginal_Likelihoods.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d341a5-e307-4061-b174-30e006097183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corner plots to check sampling within each state\n",
    "if(plotting):\n",
    "    # collect trans samples\n",
    "    transc_ensemble,model_chain,states_chain = key.get_transc_samples(discard=0,thin=thin,flat=True,returnchains=True)\n",
    "    contour_kwargs = {\"linewidths\" : 0.5}\n",
    "    data_kwargs = {\"color\" : \"slateblue\"}\n",
    "    for i in range(nstates):\n",
    "        string = 'State '+str(i)\n",
    "        print(' State; ',i,' in ',ndims[i],' dimensions')\n",
    "        fig = corner.corner(\n",
    "            flatten_extend(transc_ensemble[i]).reshape(-1,ndims[i]), \n",
    "            truths=mu[i],\n",
    "            title=string,\n",
    "            bins=40,hist_bin_factor=2,smooth=True,contour_kwargs=contour_kwargs,data_kwargs=data_kwargs\n",
    "            );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceab3723-9e6d-43c4-81d7-8c4a4813bc1c",
   "metadata": {},
   "source": [
    "Sampling within each state looks reasonable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6683b7c2-17f5-464b-ae45-78f910f0c236",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' Here is the Trans-C ensemble with\\n {} samples in state 1\\n {} samples in state 2\\n {} samples in state 3\\n'\n",
    "      .format(len(transc_ensemble[0]),len(transc_ensemble[1]),len(transc_ensemble[2])),'\\n',transc_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56875b69-0864-463b-8e82-52e632b5ae8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
